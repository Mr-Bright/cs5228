{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author by ZhangML\n",
    "def addPopulationInfo(dataset, populationInfo):\n",
    "    result = pd.DataFrame(columns=['planning_area', 'subzone', 'underadult', 'young', 'mid', 'old'])\n",
    "    age_list = [['0-4', '5-9', '10-14', '15-19'], ['20-24', '25-29', '30-34', '35-39'],\n",
    "                ['40-44', '45-49', '50-54', '55-59'], ['60-64', '65-69', '70-74',\n",
    "                                                       '75-79', '80-84', '85+']]\n",
    "    dataset.planning_area = dataset.planning_area.str.lower()\n",
    "    dataset.planning_area = dataset.planning_area.str.replace(' ', '')\n",
    "    populationInfo.plannin_area = populationInfo.plannin_area.str.lower()\n",
    "    populationInfo.plannin_area = populationInfo.plannin_area.str.replace(' ', '')\n",
    "    \n",
    "    dataset.subzone = dataset.subzone.str.lower()\n",
    "    dataset.subzone = dataset.subzone.str.replace(' ', '')\n",
    "    populationInfo.subzone = populationInfo.subzone.str.lower()\n",
    "    populationInfo.subzone = populationInfo.subzone.str.replace(' ', '')\n",
    "\n",
    "    area_list = list(populationInfo.groupby(['plannin_area', 'subzone']).groups.keys())\n",
    "    for p, s in area_list:\n",
    "        temp = populationInfo[(populationInfo.plannin_area == p) & (populationInfo.subzone == s)]\n",
    "        temp_res = [p, s]\n",
    "        for age in age_list:\n",
    "            temp_res.append(temp[temp.age_group.isin(age)]['count'].sum())\n",
    "        result.loc[len(result.index)] = temp_res\n",
    "    result = pd.merge(dataset, result, how='left', on=['planning_area', 'subzone'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author by Li Xingchen\n",
    "\n",
    "import pandas as pd\n",
    "from geopy.distance import distance\n",
    "\n",
    "def getProcessedDataset(dataset1,datasetName2) :\n",
    "\n",
    "  dataset2 = pd.read_csv('auxiliary-data/'+datasetName2+'.csv')\n",
    "\n",
    "  # Create new Series\n",
    "  nearestDistanceColName = datasetName2+'_nearestDistance/KM'\n",
    "  nearestDistanceCol = pd.Series(name=nearestDistanceColName)\n",
    "  lessHalfKMNumColName  = datasetName2+'_lessHalfKMNum'\n",
    "  lessHalfKMNumCol = pd.Series(name=lessHalfKMNumColName)\n",
    "  half2OneKMNumColName  = datasetName2+'_half2OneKMNum'\n",
    "  half2OneKMNumCol = pd.Series(name=half2OneKMNumColName)\n",
    "  one2ThreeKMNumColName  = datasetName2+'_one2ThreeKMNum'\n",
    "  one2ThreeKMNumCol = pd.Series(name=one2ThreeKMNumColName)\n",
    "\n",
    "  for index1,row in dataset1.iterrows() :\n",
    "    #print('-------------'+'train1'+'_'+str(index1)+'_begin'+'-------------')\n",
    "\n",
    "    dataset1_lat = row['latitude']\n",
    "    dataset1_lng = row['longitude']\n",
    "\n",
    "    dataset1_location = (dataset1_lat,dataset1_lng)\n",
    "\n",
    "    nearestDistance = 99999999999999999999.99\n",
    "    lessHalfKMNum = 0\n",
    "    half2OneKMNum = 0\n",
    "    one2ThreeKMNum = 0\n",
    "\n",
    "    for index,row in dataset2.iterrows() :\n",
    "      #print('========'+datasetName2+'_'+str(index)+'_begin'+'========')\n",
    "\n",
    "      dataset2_lat = row['lat']\n",
    "      dataset2_lng = row['lng']\n",
    "\n",
    "      dataset2_location = (dataset2_lat,dataset2_lng)\n",
    "\n",
    "      distance_between = distance(dataset1_location, dataset2_location).km\n",
    "\n",
    "      if distance_between < nearestDistance :\n",
    "        nearestDistance = distance_between\n",
    "\n",
    "      if distance_between < 0.5 :\n",
    "        lessHalfKMNum += 1\n",
    "      elif distance_between < 1 :\n",
    "        half2OneKMNum += 1\n",
    "      elif distance_between < 3 :\n",
    "        one2ThreeKMNum += 1\n",
    "\n",
    "      #print('nearestDistance',nearestDistance)\n",
    "      #print('lessHalfKMNum',lessHalfKMNum)\n",
    "      #print('half2OneKMNum',half2OneKMNum)\n",
    "      #print('one2ThreeKMNum',half2OneKMNum)\n",
    "      #print('========'+datasetName2+'_'+str(index)+'_end'+'========')\n",
    "\n",
    "    #print('nearestDistance',nearestDistance)\n",
    "    #print('lessHalfKMNum',lessHalfKMNum)\n",
    "    #print('half2OneKMNum',half2OneKMNum)\n",
    "    #print('one2ThreeKMNum',half2OneKMNum)\n",
    "\n",
    "    nearestDistanceCol.loc[index1] = nearestDistance\n",
    "    lessHalfKMNumCol.loc[index1] = lessHalfKMNum\n",
    "    half2OneKMNumCol.loc[index1] = half2OneKMNum\n",
    "    one2ThreeKMNumCol.loc[index1] = one2ThreeKMNum\n",
    "\n",
    "    #print('-------------'+'train1'+'_'+str(index1)+'_end'+'-------------')\n",
    "\n",
    "  dataset1 = pd.concat([dataset1, nearestDistanceCol], axis=1)\n",
    "  dataset1 = pd.concat([dataset1, lessHalfKMNumCol], axis=1)\n",
    "  dataset1 = pd.concat([dataset1, half2OneKMNumCol], axis=1)\n",
    "  dataset1 = pd.concat([dataset1, one2ThreeKMNumCol], axis=1)\n",
    "\n",
    "  return dataset1\n",
    "\n",
    "def concatAdditionalInfo(dataset) :\n",
    "\n",
    "  result = getProcessedDataset(dataset,'sg-primary-schools')\n",
    "  result = getProcessedDataset(result,'sg-commerical-centres')\n",
    "  result = getProcessedDataset(result,'sg-secondary-schools')\n",
    "  result = getProcessedDataset(result,'sg-shopping-malls')\n",
    "  result = getProcessedDataset(result,'sg-train-stations')\n",
    "  result = getProcessedDataset(result,'sg-gov-markets-hawker-centres')\n",
    "\n",
    "  #result.to_csv('result.csv', index=False)\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author by Wang Tong\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import category_encoders as ce\n",
    "\n",
    "storey_range_map = pd.DataFrame(columns=['original', 'target'])\n",
    "flat_model_map = pd.DataFrame(columns=['original', 'target'])\n",
    "planning_area_map = pd.DataFrame(columns=['original', 'target'])\n",
    "\n",
    "def preprocessData(dataset):\n",
    "    # 1. Drop outliers if any\n",
    "    dataset = dataset[dataset['floor_area_sqm'] > 0]\n",
    "    dataset = dataset[(dataset['latitude'] < 1.5) | (dataset['latitude'] > 1.2)]\n",
    "    dataset = dataset[(dataset['longitude'] < 104) | (dataset['longitude'] > 103)]\n",
    "\n",
    "    # 2. Align naming conventions for 'flat_type'\n",
    "    dataset['flat_type'].replace('-', ' ', inplace = True, regex=True)\n",
    "\n",
    "    # 3. Change format for 'month' and 'lease_commence_date'\n",
    "    # 'month'-> no. of month till now; 'lease_commence_date'-> no. of year till now\n",
    "    dataset['month'] = ((pd.to_datetime(\"today\") - pd.to_datetime(dataset['month']))/np.timedelta64(1, 'M')).astype(int)\n",
    "    dataset['lease_commence_date'] = pd.to_datetime(\"today\").year - dataset['lease_commence_date']\n",
    "    # https://stackoverflow.com/questions/54313463/pandas-datetime-to-unix-timestamp-seconds\n",
    "    #dataset['month'] = pd.to_datetime(dataset['month'])\n",
    "    #dataset['month'] = (dataset['month'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "\n",
    "    # 4. (IGNORE) Combining 'block' and 'street_name' into 1 column\n",
    "    #dataset['block_street_name'] = dataset['block'].str.upper() + ' ' + dataset['street_name'].str.upper()\n",
    "    #dataset = dataset.drop(columns=['block', 'street_name'])\n",
    "    \n",
    "    # 5. OneHotEncoder (adding 7 columns): 'flat_type' (7 cat)\n",
    "    one_hot = OneHotEncoder()\n",
    "    encoded = one_hot.fit_transform(dataset[['flat_type']])\n",
    "    column_headers = np.hstack(one_hot.categories_)\n",
    "    dataset[column_headers] = encoded.toarray()\n",
    "    \n",
    "    # 6. TargetEncoder: 'storey_range', 'planning_area', 'flat_model'\n",
    "    if 'resale_price' in dataset.columns:\n",
    "        tenc=ce.TargetEncoder()\n",
    "        # 'storey_range'\n",
    "        global storey_range_map\n",
    "        dataset = dataset.sort_values('storey_range')\n",
    "        storey_range_map['original'] = dataset['storey_range'].unique()\n",
    "        storey_range_target = tenc.fit_transform(dataset['storey_range'],dataset['resale_price'])\n",
    "        dataset = storey_range_target.join(dataset.drop('storey_range',axis = 1))\n",
    "        storey_range_map['target'] = dataset['storey_range'].unique()\n",
    "        # 'flat_model'\n",
    "        global flat_model_map\n",
    "        dataset = dataset.sort_values('flat_model')\n",
    "        flat_model_map['original'] = dataset['flat_model'].unique()\n",
    "        flat_model_target = tenc.fit_transform(dataset['flat_model'],dataset['resale_price'])\n",
    "        dataset = flat_model_target.join(dataset.drop('flat_model',axis = 1))\n",
    "        flat_model_map['target'] = dataset['flat_model'].unique()\n",
    "        # 'planning_area'\n",
    "        global planning_area_map\n",
    "        dataset = dataset.sort_values('planning_area')\n",
    "        planning_area_map['original'] = dataset['planning_area'].unique()\n",
    "        planning_area_target = tenc.fit_transform(dataset['planning_area'],dataset['resale_price'])\n",
    "        dataset = planning_area_target.join(dataset.drop('planning_area',axis = 1))\n",
    "        planning_area_map['target'] = dataset['planning_area'].unique()\n",
    "    else:\n",
    "        dataset['storey_range'] = dataset['storey_range'].map(storey_range_map.set_index('original')['target'])\n",
    "        dataset['flat_model'] = dataset['flat_model'].map(flat_model_map.set_index('original')['target'])\n",
    "        dataset['planning_area'] = dataset['planning_area'].map(planning_area_map.set_index('original')['target'])\n",
    "        \n",
    "    # 7. Drop unused columns\n",
    "    # dataset = dataset.drop(columns=['elevation', 'eco_category', 'town', 'flat_type',\n",
    "    #                                 'storey_range', 'flat_model', 'region','block',\n",
    "    #                                 'subzone', 'street_name', 'latitude', 'longitude'])\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('TrainResultAll.xlsx')\n",
    "test = pd.read_csv('TestResultAll.csv')\n",
    "population_info = pd.read_csv('auxiliary-data/sg-population-demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = addPopulationInfo(train, population_info)\n",
    "test = addPopulationInfo(test, population_info)\n",
    "\n",
    "train = preprocessData(train)\n",
    "test = preprocessData(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(0)\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>planning_area</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>month</th>\n",
       "      <th>town</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>block</th>\n",
       "      <th>street_name</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>eco_category</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>mid</th>\n",
       "      <th>old</th>\n",
       "      <th>1 room</th>\n",
       "      <th>2 room</th>\n",
       "      <th>3 room</th>\n",
       "      <th>4 room</th>\n",
       "      <th>5 room</th>\n",
       "      <th>executive</th>\n",
       "      <th>multi generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112008</th>\n",
       "      <td>266071.993631</td>\n",
       "      <td>228834.110584</td>\n",
       "      <td>299298.260782</td>\n",
       "      <td>231</td>\n",
       "      <td>ang mo kio</td>\n",
       "      <td>4 room</td>\n",
       "      <td>112</td>\n",
       "      <td>ang mo kio avenue 4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>...</td>\n",
       "      <td>6180</td>\n",
       "      <td>7550</td>\n",
       "      <td>6100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284264</th>\n",
       "      <td>266071.993631</td>\n",
       "      <td>228834.110584</td>\n",
       "      <td>277884.021822</td>\n",
       "      <td>250</td>\n",
       "      <td>ang mo kio</td>\n",
       "      <td>3 room</td>\n",
       "      <td>435</td>\n",
       "      <td>Ang Mo Kio Avenue 10</td>\n",
       "      <td>67.0</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>...</td>\n",
       "      <td>7400</td>\n",
       "      <td>8640</td>\n",
       "      <td>7330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193152</th>\n",
       "      <td>266071.993631</td>\n",
       "      <td>228834.110584</td>\n",
       "      <td>277884.021822</td>\n",
       "      <td>136</td>\n",
       "      <td>ang mo kio</td>\n",
       "      <td>3 room</td>\n",
       "      <td>604</td>\n",
       "      <td>Ang Mo Kio Avenue 5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>...</td>\n",
       "      <td>7150</td>\n",
       "      <td>8520</td>\n",
       "      <td>5600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284220</th>\n",
       "      <td>266071.993631</td>\n",
       "      <td>228834.110584</td>\n",
       "      <td>277884.021822</td>\n",
       "      <td>216</td>\n",
       "      <td>ang mo kio</td>\n",
       "      <td>3 room</td>\n",
       "      <td>523</td>\n",
       "      <td>ang mo kio avenue 5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>...</td>\n",
       "      <td>8380</td>\n",
       "      <td>9280</td>\n",
       "      <td>6940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40703</th>\n",
       "      <td>266071.993631</td>\n",
       "      <td>228834.110584</td>\n",
       "      <td>344712.326690</td>\n",
       "      <td>166</td>\n",
       "      <td>ang mo kio</td>\n",
       "      <td>3 room</td>\n",
       "      <td>577</td>\n",
       "      <td>Ang Mo Kio Avenue 10</td>\n",
       "      <td>67.0</td>\n",
       "      <td>uncategorized</td>\n",
       "      <td>...</td>\n",
       "      <td>8380</td>\n",
       "      <td>9280</td>\n",
       "      <td>6940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        planning_area     flat_model   storey_range  month        town  \\\n",
       "112008  266071.993631  228834.110584  299298.260782    231  ang mo kio   \n",
       "284264  266071.993631  228834.110584  277884.021822    250  ang mo kio   \n",
       "193152  266071.993631  228834.110584  277884.021822    136  ang mo kio   \n",
       "284220  266071.993631  228834.110584  277884.021822    216  ang mo kio   \n",
       "40703   266071.993631  228834.110584  344712.326690    166  ang mo kio   \n",
       "\n",
       "       flat_type block           street_name  floor_area_sqm   eco_category  \\\n",
       "112008    4 room   112   ang mo kio avenue 4            98.0  uncategorized   \n",
       "284264    3 room   435  Ang Mo Kio Avenue 10            67.0  uncategorized   \n",
       "193152    3 room   604   Ang Mo Kio Avenue 5            67.0  uncategorized   \n",
       "284220    3 room   523   ang mo kio avenue 5            68.0  uncategorized   \n",
       "40703     3 room   577  Ang Mo Kio Avenue 10            67.0  uncategorized   \n",
       "\n",
       "        ...  young   mid   old  1 room 2 room 3 room  4 room  5 room  \\\n",
       "112008  ...   6180  7550  6100     0.0    0.0    0.0     1.0     0.0   \n",
       "284264  ...   7400  8640  7330     0.0    0.0    1.0     0.0     0.0   \n",
       "193152  ...   7150  8520  5600     0.0    0.0    1.0     0.0     0.0   \n",
       "284220  ...   8380  9280  6940     0.0    0.0    1.0     0.0     0.0   \n",
       "40703   ...   8380  9280  6940     0.0    0.0    1.0     0.0     0.0   \n",
       "\n",
       "        executive  multi generation  \n",
       "112008        0.0               0.0  \n",
       "284264        0.0               0.0  \n",
       "193152        0.0               0.0  \n",
       "284220        0.0               0.0  \n",
       "40703         0.0               0.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('processed_train', index=0)\n",
    "test.to_csv('processed_test',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['elevation', 'eco_category', 'town', 'flat_type',\n",
    "                                    'storey_range', 'flat_model', 'region','block',\n",
    "                                    'subzone', 'street_name', 'latitude', 'longitude'])\n",
    "test = test.drop(columns=['elevation', 'eco_category', 'town', 'flat_type',\n",
    "                                    'storey_range', 'flat_model', 'region','block',\n",
    "                                    'subzone', 'street_name', 'latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.resale_price\n",
    "train_x = train.drop(\"resale_price\", axis=1)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "regressor.fit(train_x, train_y)\n",
    "predict_y = regressor.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_48796\\2735913900.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mregressor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mRandomForestRegressor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_estimators\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[0mregressor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m \u001B[0mpredict_y\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mregressor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    465\u001B[0m                     \u001B[0mn_samples_bootstrap\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mn_samples_bootstrap\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    466\u001B[0m                 )\n\u001B[1;32m--> 467\u001B[1;33m                 \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mt\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrees\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    468\u001B[0m             )\n\u001B[0;32m    469\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1049\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1050\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m                 \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    862\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    863\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 864\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    865\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    866\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    780\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    781\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 782\u001B[1;33m             \u001B[0mjob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    783\u001B[0m             \u001B[1;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    784\u001B[0m             \u001B[1;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m         \u001B[1;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 208\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    209\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    570\u001B[0m         \u001B[1;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    571\u001B[0m         \u001B[1;31m# arguments in memory\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 572\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    573\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    262\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    263\u001B[0m             return [func(*args, **kwargs)\n\u001B[1;32m--> 264\u001B[1;33m                     for func, args, kwargs in self.items]\n\u001B[0m\u001B[0;32m    265\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    266\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__reduce__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    262\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    263\u001B[0m             return [func(*args, **kwargs)\n\u001B[1;32m--> 264\u001B[1;33m                     for func, args, kwargs in self.items]\n\u001B[0m\u001B[0;32m    265\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    266\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__reduce__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    214\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    215\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mconfig_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 216\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    217\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    218\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001B[0m in \u001B[0;36m_parallel_build_trees\u001B[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001B[0m\n\u001B[0;32m    183\u001B[0m             \u001B[0mcurr_sample_weight\u001B[0m \u001B[1;33m*=\u001B[0m \u001B[0mcompute_sample_weight\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"balanced\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindices\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mindices\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    184\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 185\u001B[1;33m         \u001B[0mtree\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcurr_sample_weight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcheck_input\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    186\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    187\u001B[0m         \u001B[0mtree\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcheck_input\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[0;32m   1318\u001B[0m             \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1319\u001B[0m             \u001B[0mcheck_input\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcheck_input\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1320\u001B[1;33m             \u001B[0mX_idx_sorted\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX_idx_sorted\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1321\u001B[0m         )\n\u001B[0;32m   1322\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[0;32m    418\u001B[0m             )\n\u001B[0;32m    419\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 420\u001B[1;33m         \u001B[0mbuilder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbuild\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtree_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    421\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    422\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_outputs_\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mis_classifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "result.insert(result.shape[0], 'Id', range(len(predict_y)))\n",
    "result.insert(result.shape[0], 'Predicted', predict_y)\n",
    "result.to_csv('result.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
