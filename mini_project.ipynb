{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 额外数据读入都放到这个块里\n",
    "\n",
    "population_info = pd.read_csv('auxiliary-data/sg-population-demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author by ZhangML\n",
    "def addPopulationInfo(dataset, populationInfo):\n",
    "    result = pd.DataFrame(columns=['planning_area', 'subzone', 'underadult', 'young', 'mid', 'old'])\n",
    "    age_list = [['0-4', '5-9', '10-14', '15-19'], ['20-24', '25-29', '30-34', '35-39'],\n",
    "                ['40-44', '45-49', '50-54', '55-59'], ['60-64', '65-69', '70-74',\n",
    "                                                       '75-79', '80-84', '85+']]\n",
    "    dataset.planning_area = dataset.planning_area.str.lower()\n",
    "    dataset.planning_area = dataset.planning_area.str.replace(' ', '')\n",
    "    populationInfo.planning_area = populationInfo.planning_area.str.lower()\n",
    "    populationInfo.planning_area = populationInfo.planning_area.str.replace(' ', '')\n",
    "    area_list = list(populationInfo.groupby(['plannin_area', 'subzone']).groups.keys())\n",
    "    for p, s in area_list:\n",
    "        temp = populationInfo[(populationInfo.plannin_area == p) & (populationInfo.subzone == s)]\n",
    "        temp_res = [p, s]\n",
    "        for age in age_list:\n",
    "            temp_res.append(temp[temp.age_group.isin(age)]['count'].sum())\n",
    "        result.loc[len(result.index)] = temp_res\n",
    "    result = pd.merge(dataset, result, how='left', on=['planning_area', 'subzone'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author by Li Xingchen\n",
    "\n",
    "import pandas as pd\n",
    "from geopy.distance import distance\n",
    "\n",
    "def getProcessedDataset(dataset1,datasetName2) :\n",
    "\n",
    "  dataset2 = pd.read_csv('auxiliary-data/'+datasetName2+'.csv')\n",
    "\n",
    "  # Create new Series\n",
    "  nearestDistanceColName = datasetName2+'_nearestDistance/KM'\n",
    "  nearestDistanceCol = pd.Series(name=nearestDistanceColName)\n",
    "  lessHalfKMNumColName  = datasetName2+'_lessHalfKMNum'\n",
    "  lessHalfKMNumCol = pd.Series(name=lessHalfKMNumColName)\n",
    "  half2OneKMNumColName  = datasetName2+'_half2OneKMNum'\n",
    "  half2OneKMNumCol = pd.Series(name=half2OneKMNumColName)\n",
    "  one2ThreeKMNumColName  = datasetName2+'_one2ThreeKMNum'\n",
    "  one2ThreeKMNumCol = pd.Series(name=one2ThreeKMNumColName)\n",
    "\n",
    "  for index1,row in dataset1.iterrows() :\n",
    "    #print('-------------'+'train1'+'_'+str(index1)+'_begin'+'-------------')\n",
    "\n",
    "    dataset1_lat = row['latitude']\n",
    "    dataset1_lng = row['longitude']\n",
    "\n",
    "    dataset1_location = (dataset1_lat,dataset1_lng)\n",
    "\n",
    "    nearestDistance = 99999999999999999999.99\n",
    "    lessHalfKMNum = 0\n",
    "    half2OneKMNum = 0\n",
    "    one2ThreeKMNum = 0\n",
    "\n",
    "    for index,row in dataset2.iterrows() :\n",
    "      #print('========'+datasetName2+'_'+str(index)+'_begin'+'========')\n",
    "\n",
    "      dataset2_lat = row['lat']\n",
    "      dataset2_lng = row['lng']\n",
    "\n",
    "      dataset2_location = (dataset2_lat,dataset2_lng)\n",
    "\n",
    "      distance_between = distance(dataset1_location, dataset2_location).km\n",
    "\n",
    "      if distance_between < nearestDistance :\n",
    "        nearestDistance = distance_between\n",
    "\n",
    "      if distance_between < 0.5 :\n",
    "        lessHalfKMNum += 1\n",
    "      elif distance_between < 1 :\n",
    "        half2OneKMNum += 1\n",
    "      elif distance_between < 3 :\n",
    "        one2ThreeKMNum += 1\n",
    "\n",
    "      #print('nearestDistance',nearestDistance)\n",
    "      #print('lessHalfKMNum',lessHalfKMNum)\n",
    "      #print('half2OneKMNum',half2OneKMNum)\n",
    "      #print('one2ThreeKMNum',half2OneKMNum)\n",
    "      #print('========'+datasetName2+'_'+str(index)+'_end'+'========')\n",
    "\n",
    "    #print('nearestDistance',nearestDistance)\n",
    "    #print('lessHalfKMNum',lessHalfKMNum)\n",
    "    #print('half2OneKMNum',half2OneKMNum)\n",
    "    #print('one2ThreeKMNum',half2OneKMNum)\n",
    "\n",
    "    nearestDistanceCol.loc[index1] = nearestDistance\n",
    "    lessHalfKMNumCol.loc[index1] = lessHalfKMNum\n",
    "    half2OneKMNumCol.loc[index1] = half2OneKMNum\n",
    "    one2ThreeKMNumCol.loc[index1] = one2ThreeKMNum\n",
    "\n",
    "    #print('-------------'+'train1'+'_'+str(index1)+'_end'+'-------------')\n",
    "\n",
    "  dataset1 = pd.concat([dataset1, nearestDistanceCol], axis=1)\n",
    "  dataset1 = pd.concat([dataset1, lessHalfKMNumCol], axis=1)\n",
    "  dataset1 = pd.concat([dataset1, half2OneKMNumCol], axis=1)\n",
    "  dataset1 = pd.concat([dataset1, one2ThreeKMNumCol], axis=1)\n",
    "\n",
    "  return dataset1\n",
    "\n",
    "def concatAdditionalInfo(dataset) :\n",
    "\n",
    "  result = getProcessedDataset(dataset,'sg-primary-schools')\n",
    "  result = getProcessedDataset(result,'sg-commerical-centres')\n",
    "  result = getProcessedDataset(result,'sg-secondary-schools')\n",
    "  result = getProcessedDataset(result,'sg-shopping-malls')\n",
    "  result = getProcessedDataset(result,'sg-train-stations')\n",
    "  result = getProcessedDataset(result,'sg-gov-markets-hawker-centres')\n",
    "\n",
    "  #result.to_csv('result.csv', index=False)\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mr.Bright\\.conda\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  if sys.path[0] == \"\":\n",
      "C:\\Users\\Mr.Bright\\.conda\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \n",
      "C:\\Users\\Mr.Bright\\.conda\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \n",
      "C:\\Users\\Mr.Bright\\.conda\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_25076\\371870118.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[0mtrain\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0maddPopulationInfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpopulation_info\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[0mtest\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0maddPopulationInfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpopulation_info\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 62\u001B[1;33m \u001B[0mtrain\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconcatAdditionalInfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     63\u001B[0m \u001B[0mtest\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconcatAdditionalInfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_25076\\3342842382.py\u001B[0m in \u001B[0;36mconcatAdditionalInfo\u001B[1;34m(dataset)\u001B[0m\n\u001B[0;32m     78\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mconcatAdditionalInfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     79\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 80\u001B[1;33m   \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetProcessedDataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'sg-primary-schools'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     81\u001B[0m   \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetProcessedDataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'sg-commerical-centres'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     82\u001B[0m   \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetProcessedDataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'sg-secondary-schools'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_25076\\3342842382.py\u001B[0m in \u001B[0;36mgetProcessedDataset\u001B[1;34m(dataset1, datasetName2)\u001B[0m\n\u001B[0;32m     34\u001B[0m       \u001B[1;31m#print('========'+datasetName2+'_'+str(index)+'_begin'+'========')\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 36\u001B[1;33m       \u001B[0mdataset2_lat\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrow\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'lat'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     37\u001B[0m       \u001B[0mdataset2_lng\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrow\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'lng'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\pandas\\core\\series.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    927\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    928\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__getitem__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 929\u001B[1;33m         \u001B[0mkey\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_if_callable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    930\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    931\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mkey\u001B[0m \u001B[1;32mis\u001B[0m \u001B[0mEllipsis\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# author by Wang Tong\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import category_encoders as ce\n",
    "\n",
    "storey_range_target = pd.DataFrame()\n",
    "flat_model_target = pd.DataFrame()\n",
    "planning_area_target = pd.DataFrame()\n",
    "\n",
    "def preprocessData(dataset):\n",
    "    # 1. Drop outliers if any\n",
    "    dataset = dataset[dataset['floor_area_sqm'] > 0]\n",
    "    dataset = dataset[(dataset['latitude'] < 1.5) | (dataset['latitude'] > 1.2)]\n",
    "    dataset = dataset[(dataset['longitude'] < 104) | (dataset['longitude'] > 103)]\n",
    "\n",
    "    # 2. Align naming conventions for 'flat_type'\n",
    "    dataset['flat_type'].replace('-', ' ', inplace = True, regex=True)\n",
    "\n",
    "    # 3. Change Datetime format for 'month'\n",
    "    # https://stackoverflow.com/questions/54313463/pandas-datetime-to-unix-timestamp-seconds\n",
    "    dataset['month'] = pd.to_datetime(dataset['month'])\n",
    "    dataset['month'] = (dataset['month'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "\n",
    "    # 4. (IGNORE) Combining 'block' and 'street_name' into 1 column\n",
    "    #dataset['block_street_name'] = dataset['block'].str.upper() + ' ' + dataset['street_name'].str.upper()\n",
    "    #dataset = dataset.drop(columns=['block', 'street_name'])\n",
    "    \n",
    "    # 5. OneHotEncoder (adding 7 columns): 'flat_type' (7 cat)\n",
    "    one_hot = OneHotEncoder()\n",
    "    encoded = one_hot.fit_transform(dataset[['flat_type']])\n",
    "    column_headers = np.hstack(one_hot.categories_)\n",
    "    dataset[column_headers] = encoded.toarray()\n",
    "    \n",
    "    # 6. TargetEncoder: 'storey_range', 'planning_area', 'flat_model'\n",
    "    if 'resale_price' in dataset.columns:\n",
    "        tenc=ce.TargetEncoder()\n",
    "        # 'storey_range'\n",
    "        global storey_range_target \n",
    "        storey_range_target = tenc.fit_transform(dataset['storey_range'],dataset['resale_price'])\n",
    "        dataset = storey_range_target.join(dataset.drop('storey_range',axis = 1))\n",
    "        # 'flat_model'\n",
    "        global flat_model_target\n",
    "        flat_model_target = tenc.fit_transform(dataset['flat_model'],dataset['resale_price'])\n",
    "        dataset = flat_model_target.join(dataset.drop('flat_model',axis = 1))\n",
    "        # 'planning_area'\n",
    "        global planning_area_target\n",
    "        planning_area_target = tenc.fit_transform(dataset['planning_area'],dataset['resale_price'])\n",
    "        dataset = planning_area_target.join(dataset.drop('planning_area',axis = 1))\n",
    "    else:\n",
    "        dataset = storey_range_target.join(dataset.drop('storey_range',axis = 1))\n",
    "        dataset = flat_model_target.join(dataset.drop('flat_model',axis = 1))\n",
    "        dataset = planning_area_target.join(dataset.drop('planning_area',axis = 1))\n",
    "        \n",
    "    # 7. Drop unused columns\n",
    "    # dataset = dataset.drop(columns=['elevation', 'eco_category', 'town', 'flat_type',\n",
    "    #                                 'storey_range', 'flat_model', 'region','block',\n",
    "    #                                 'subzone', 'street_name', 'latitude', 'longitude'])\n",
    "    \n",
    "    return dataset\n",
    "train = addPopulationInfo(train, population_info)\n",
    "test = addPopulationInfo(test, population_info)\n",
    "train = concatAdditionalInfo(train)\n",
    "test = concatAdditionalInfo(test)\n",
    "\n",
    "train = preprocessData(train)\n",
    "test = preprocessData(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('processed_train.csv')\n",
    "test = pd.read_csv('processed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['elevation', 'eco_category', 'town', 'flat_type',\n",
    "                                    'storey_range', 'flat_model', 'region','block',\n",
    "                                    'subzone', 'street_name', 'latitude', 'longitude','Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns=['elevation', 'eco_category', 'town', 'flat_type',\n",
    "                                    'storey_range', 'flat_model', 'region','block',\n",
    "                                    'subzone', 'street_name', 'latitude', 'longitude','Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_51296\\2970242744.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misnan\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0many\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misnan\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0many\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m==\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m__array_ufunc__\u001B[1;34m(self, ufunc, method, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   2030\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mufunc\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mufunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mAny\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mAny\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2031\u001B[0m     ):\n\u001B[1;32m-> 2032\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0marraylike\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray_ufunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mufunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2033\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2034\u001B[0m     \u001B[1;31m# ideally we would define this to avoid the getattr checks, but\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\pandas\\core\\arraylike.py\u001B[0m in \u001B[0;36marray_ufunc\u001B[1;34m(self, ufunc, method, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m    370\u001B[0m             \u001B[1;31m# take this path if there are no kwargs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    371\u001B[0m             \u001B[0mmgr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_mgr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 372\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmgr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mufunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    373\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    374\u001B[0m             \u001B[1;31m# otherwise specific ufunc methods (eg np.<ufunc>.accumulate(..))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001B[0m\n\u001B[0;32m    323\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    324\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mcallable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 325\u001B[1;33m                     \u001B[0mapplied\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mb\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    326\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    327\u001B[0m                     \u001B[0mapplied\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self, func, **kwargs)\u001B[0m\n\u001B[0;32m    379\u001B[0m         \"\"\"\n\u001B[0;32m    380\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merrstate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"ignore\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 381\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    382\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    383\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_split_op_result\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "np.isnan(train).any()[np.isnan(train).any()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>planning_area</th>\n",
       "      <th>subzone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7169</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15055</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19665</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26727</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27592</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422795</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424835</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426748</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427380</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430762</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       planning_area   subzone\n",
       "7169    downtowncore  cityhall\n",
       "15055   downtowncore  cityhall\n",
       "19665   downtowncore  cityhall\n",
       "26727   downtowncore  cityhall\n",
       "27592   downtowncore  cityhall\n",
       "...              ...       ...\n",
       "422795  downtowncore  cityhall\n",
       "424835  downtowncore  cityhall\n",
       "426748  downtowncore  cityhall\n",
       "427380  downtowncore  cityhall\n",
       "430762  downtowncore  cityhall\n",
       "\n",
       "[154 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.isnull().T.any()][['planning_area', 'subzone']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>planning_area</th>\n",
       "      <th>subzone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13064</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13347</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14825</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17770</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22170</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22301</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24615</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26340</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28853</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31936</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33360</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36240</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39851</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42447</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42455</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48915</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49310</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53312</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55981</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56474</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60387</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60757</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66258</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71119</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74248</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74703</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76887</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77094</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78158</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78679</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79434</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82610</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82737</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90299</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90601</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92225</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94684</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94694</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98524</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99187</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100701</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101553</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102705</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105037</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105824</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107931</th>\n",
       "      <td>downtowncore</td>\n",
       "      <td>cityhall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       planning_area   subzone\n",
       "13064   downtowncore  cityhall\n",
       "13347   downtowncore  cityhall\n",
       "14825   downtowncore  cityhall\n",
       "17770   downtowncore  cityhall\n",
       "22170   downtowncore  cityhall\n",
       "22301   downtowncore  cityhall\n",
       "24615   downtowncore  cityhall\n",
       "26340   downtowncore  cityhall\n",
       "28853   downtowncore  cityhall\n",
       "31936   downtowncore  cityhall\n",
       "33360   downtowncore  cityhall\n",
       "36240   downtowncore  cityhall\n",
       "39851   downtowncore  cityhall\n",
       "42447   downtowncore  cityhall\n",
       "42455   downtowncore  cityhall\n",
       "48915   downtowncore  cityhall\n",
       "49310   downtowncore  cityhall\n",
       "53312   downtowncore  cityhall\n",
       "55981   downtowncore  cityhall\n",
       "56474   downtowncore  cityhall\n",
       "60387   downtowncore  cityhall\n",
       "60757   downtowncore  cityhall\n",
       "66258   downtowncore  cityhall\n",
       "71119   downtowncore  cityhall\n",
       "74248   downtowncore  cityhall\n",
       "74703   downtowncore  cityhall\n",
       "76887   downtowncore  cityhall\n",
       "77094   downtowncore  cityhall\n",
       "78158   downtowncore  cityhall\n",
       "78679   downtowncore  cityhall\n",
       "79434   downtowncore  cityhall\n",
       "82610   downtowncore  cityhall\n",
       "82737   downtowncore  cityhall\n",
       "90299   downtowncore  cityhall\n",
       "90601   downtowncore  cityhall\n",
       "92225   downtowncore  cityhall\n",
       "94684   downtowncore  cityhall\n",
       "94694   downtowncore  cityhall\n",
       "98524   downtowncore  cityhall\n",
       "99187   downtowncore  cityhall\n",
       "100701  downtowncore  cityhall\n",
       "101553  downtowncore  cityhall\n",
       "102705  downtowncore  cityhall\n",
       "105037  downtowncore  cityhall\n",
       "105824  downtowncore  cityhall\n",
       "107931  downtowncore  cityhall"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.isnull().T.any()][['planning_area', 'subzone']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431732"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431732"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.resale_price\n",
    "train_x = train.drop(\"resale_price\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_51296\\2535186022.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mregressor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mRandomForestRegressor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_estimators\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mregressor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    326\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    327\u001B[0m         X, y = self._validate_data(\n\u001B[1;32m--> 328\u001B[1;33m             \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmulti_output\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"csc\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mDTYPE\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    329\u001B[0m         )\n\u001B[0;32m    330\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0msample_weight\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    579\u001B[0m                 \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    580\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 581\u001B[1;33m                 \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_X_y\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    582\u001B[0m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    583\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m    974\u001B[0m         \u001B[0mensure_min_samples\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mensure_min_samples\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    975\u001B[0m         \u001B[0mensure_min_features\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mensure_min_features\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 976\u001B[1;33m         \u001B[0mestimator\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mestimator\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    977\u001B[0m     )\n\u001B[0;32m    978\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[0;32m    798\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    799\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mforce_all_finite\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 800\u001B[1;33m             \u001B[0m_assert_all_finite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mallow_nan\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mforce_all_finite\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"allow-nan\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    801\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    802\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mensure_min_samples\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m_assert_all_finite\u001B[1;34m(X, allow_nan, msg_dtype)\u001B[0m\n\u001B[0;32m    114\u001B[0m             raise ValueError(\n\u001B[0;32m    115\u001B[0m                 msg_err.format(\n\u001B[1;32m--> 116\u001B[1;33m                     \u001B[0mtype_err\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmsg_dtype\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mmsg_dtype\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    117\u001B[0m                 )\n\u001B[0;32m    118\u001B[0m             )\n",
      "\u001B[1;31mValueError\u001B[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "regressor.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = regressor.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "result.insert(result.shape[0], 'Id', range(len(predict_y)))\n",
    "result.insert(result.shape[0], 'Predicted', predict_y)\n",
    "result.to_csv('result.csv', index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
